{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Content</th>\n",
       "      <th>Action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/2/2018</td>\n",
       "      <td>If Procter &amp; Gamble were sponsoring a 2018 adv...</td>\n",
       "      <td>Buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/2/2018</td>\n",
       "      <td>The golden age of television programming is he...</td>\n",
       "      <td>Buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/2/2018</td>\n",
       "      <td>Please take your seats.It is that time of year...</td>\n",
       "      <td>Buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/2/2018</td>\n",
       "      <td>HONG KONG — One of the world’s most valuable s...</td>\n",
       "      <td>Buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/2/2018</td>\n",
       "      <td>WASHINGTON — United States officials have effe...</td>\n",
       "      <td>Buy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date                                            Content Action\n",
       "0  1/2/2018  If Procter & Gamble were sponsoring a 2018 adv...    Buy\n",
       "1  1/2/2018  The golden age of television programming is he...    Buy\n",
       "2  1/2/2018  Please take your seats.It is that time of year...    Buy\n",
       "3  1/2/2018  HONG KONG — One of the world’s most valuable s...    Buy\n",
       "4  1/2/2018  WASHINGTON — United States officials have effe...    Buy"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#import data\n",
    "stock_df = pd.read_csv('2buysell.csv')\n",
    "stock_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Fifi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "#clean up the text\n",
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "#function to clean the text\n",
    "def clean_text(text):\n",
    "    text = text.lower() # lowercase text\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
    "    text = BAD_SYMBOLS_RE.sub('', text) # delete symbols which are in BAD_SYMBOLS_RE from text\n",
    "    \n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # delete stopwords from text\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words AFTER clean up: 2663855\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Content</th>\n",
       "      <th>Action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/2/2018</td>\n",
       "      <td>procter gamble sponsoring 2018 advertisement a...</td>\n",
       "      <td>Buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/2/2018</td>\n",
       "      <td>golden age television programming heading gris...</td>\n",
       "      <td>Buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/2/2018</td>\n",
       "      <td>please take seatsit time year annual closing d...</td>\n",
       "      <td>Buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/2/2018</td>\n",
       "      <td>hong kong one worlds valuable startups got way...</td>\n",
       "      <td>Buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/2/2018</td>\n",
       "      <td>washington united states officials effectively...</td>\n",
       "      <td>Buy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date                                            Content Action\n",
       "0  1/2/2018  procter gamble sponsoring 2018 advertisement a...    Buy\n",
       "1  1/2/2018  golden age television programming heading gris...    Buy\n",
       "2  1/2/2018  please take seatsit time year annual closing d...    Buy\n",
       "3  1/2/2018  hong kong one worlds valuable startups got way...    Buy\n",
       "4  1/2/2018  washington united states officials effectively...    Buy"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#apply function to each row in the dataframe\n",
    "stock_df['Content'] = buysell_df['Content'].apply(clean_text)\n",
    "#number of words after clean up\n",
    "print(f\"Number of words AFTER clean up: {stock_df['Content'].apply(lambda x: len(x.split(' '))).sum()}\") \n",
    "stock_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'procter gamble sponsoring 2018 advertisement avoiding activists might include inhouse remedy removing corporate stains investors seeking new strategies dividends executive changes board seats arent going away anything siege pg nelson peltz whose trian partners gained directors seat 10month campaign embolden others take cause resistance isnt futile needs carefully consideredfrom general motors whole foods company limits 2017 pg proved size defense 230 billion conglomerate largest ever target proxy fight companies market capitalization 10 billion made 214 percent targets first 11 months 2017 two percentage points previous year according activist insight expect trend continue 2018 even though activists went home emptyhanded cases 11 months wasnt case previous yearfor companies best defense good offense gms mary barra handily fended david einhorns attempt split stock helped already begun address stocks discount selling automakers european brands mr einhorn launched campaign carefully outlined companys longterm strategy automatic data processing sent bill ackman packing pointing efforts transform technology hedgefund managers comparatively poor performancefor activists sharp instincts finely honed demands hold key success mr peltz made clear wasnt seeking break pg sought single board seat push new blood management greater emphasis new products mergers acquisitions defiant 10month defense chief executive david taylor seemed proportion activists ask ultimately undercut mr taylors credibility look executives follow example general electrics john flannery enlisted mr peltz ally giving trian board seat without proxy fightpgs boardroom makeover offers companies opportunity wash dirty laundry entrenchment egocentricity poor performance without clear plan checklist activist success chief executives board members looking fend need add softener pride starch corporate plans'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_df['Content'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete rows with no content\n",
    "\n",
    "#keep a count of how many you delete\n",
    "bad_rows = []\n",
    "for i in range(0,stock_df.shape[0]):\n",
    "    #if the number of characters is below 100\n",
    "    if len(stock_df['Content'].iloc[i])<100:\n",
    "        bad_rows.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4574, 3)\n",
      "       Date                                            Content Action\n",
      "0  1/2/2018  procter gamble sponsoring 2018 advertisement a...    Buy\n",
      "1  1/2/2018  golden age television programming heading gris...    Buy\n",
      "2  1/2/2018  please take seatsit time year annual closing d...    Buy\n",
      "3  1/2/2018  hong kong one worlds valuable startups got way...    Buy\n",
      "4  1/2/2018  washington united states officials effectively...    Buy\n"
     ]
    }
   ],
   "source": [
    "print(stock_df.shape)\n",
    "print(stock_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data set\n",
    "X = stock_df.Content\n",
    "y = stock_df.Action\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.3879781420765027\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Buy       0.00      0.00      0.00       293\n",
      "        Hold       0.39      1.00      0.56       354\n",
      "        Sell       1.00      0.00      0.01       268\n",
      "\n",
      "   micro avg       0.39      0.39      0.39       915\n",
      "   macro avg       0.46      0.33      0.19       915\n",
      "weighted avg       0.44      0.39      0.22       915\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fifi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "#convert to a matrix of token counts (CountVectorizer)\n",
    "#then transform a count matrix to a normalized tf-idf representation (tf-idf transformer)\n",
    "nb = Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', MultinomialNB()),\n",
    "              ])\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
