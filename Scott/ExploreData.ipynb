{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore Data\n",
    "Notebook is to explore the Yelp data to determine if it can be used on a local instance of Juypter Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- Dependences\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#- Path to dataset\n",
    "downloadDataPath = \"/Users/thefixermac/Development_Data/Workshop/DataScience_FinalProject\"\n",
    "\n",
    "businessPath = os.path.join(downloadDataPath, \"yelp_dataset\", \"business.json\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 Business.json\n",
    "Oepn the Yelp dataset for the business; 138 MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "business_df = pd.read_json(businessPath, lines=True)\n",
    "\n",
    "business_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- Information on Cities\n",
    "\n",
    "#- Get Cities\n",
    "businessCities = business_df.city.unique()\n",
    "\n",
    "#- Count\n",
    "print(f'Total distict cities: {len(businessCities)}')\n",
    "\n",
    "#- Printout Cities\n",
    "print(\" \")\n",
    "      \n",
    "for city in businessCities:\n",
    "    print(city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 Reviews\n",
    "Attempt to open the review.json that is 5.35 GB file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data: 1\n",
      "Loading data: 2\n",
      "Loading data: 3\n",
      "Loading data: 4\n",
      "Loading data: 5\n",
      "Loading data: 6\n",
      "Loading data: 7\n",
      "Loading data: 8\n",
      "Loading data: 9\n",
      "Loading data: 10\n",
      "Loading data: 11\n",
      "Loading data: 12\n",
      "Loading data: 13\n",
      "Loading data: 14\n",
      "Loading data: 15\n",
      "Loading data: 16\n",
      "Loading data: 17\n",
      "Loading data: 18\n",
      "Loading data: 19\n",
      "Loading data: 20\n",
      "Loading data: 21\n",
      "Loading data: 22\n",
      "Loading data: 23\n",
      "Loading data: 24\n",
      "Loading data: 25\n",
      "Loading data: 26\n",
      "Loading data: 27\n",
      "Loading data: 28\n",
      "Loading data: 29\n",
      "Loading data: 30\n",
      "Loading data: 31\n",
      "Loading data: 32\n",
      "Loading data: 33\n",
      "Loading data: 34\n",
      "Loading data: 35\n",
      "Loading data: 36\n",
      "Loading data: 37\n",
      "Loading data: 38\n",
      "Loading data: 39\n",
      "Loading data: 40\n",
      "Loading data: 41\n",
      "Loading data: 42\n",
      "Loading data: 43\n",
      "Loading data: 44\n",
      "Loading data: 45\n",
      "Loading data: 46\n",
      "Loading data: 47\n",
      "Loading data: 48\n",
      "Loading data: 49\n",
      "Loading data: 50\n",
      "Loading data: 51\n",
      "Loading data: 52\n",
      "Loading data: 53\n",
      "Loading data: 54\n",
      "Loading data: 55\n",
      "Loading data: 56\n",
      "Loading data: 57\n",
      "Loading data: 58\n",
      "Loading data: 59\n",
      "Loading data: 60\n",
      "Loading data: 61\n",
      "Loading data: 62\n",
      "Loading data: 63\n",
      "Loading data: 64\n",
      "Loading data: 65\n",
      "Loading data: 66\n",
      "Loading data: 67\n",
      "Completed loading data\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#- Create Path\n",
    "reviewPath = os.path.join(downloadDataPath, \"yelp_dataset\", \"review.json\")\n",
    "\n",
    "\n",
    "#- Chunk File\n",
    "chunkSize = 100000\n",
    "\n",
    "reviewJsonReader = pd.read_json(reviewPath, lines=True, chunksize=chunkSize)\n",
    "\n",
    "\n",
    "#- Load into Dataframe\n",
    "counter = 0\n",
    "review_df = pd.DataFrame()\n",
    "\n",
    "for reader in reviewJsonReader:\n",
    "    \n",
    "    counter +=1\n",
    "    print(f'Loading data: {counter}')\n",
    "    \n",
    "    review_df = pd.concat([review_df, reader])\n",
    "    \n",
    "    \n",
    "    \n",
    "print(\"Completed loading data\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6685900, 9)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "      <th>funny</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ujmEBvifdJM6h6RLv4wQIg</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-05-07 04:34:36</td>\n",
       "      <td>1</td>\n",
       "      <td>Q1sbwvVQXV2734tPgoKj4Q</td>\n",
       "      <td>1</td>\n",
       "      <td>Total bill for this horrible service? Over $8G...</td>\n",
       "      <td>6</td>\n",
       "      <td>hG7b0MtEbXx5QzbzE6C_VA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NZnhc2sEQy3RmzKTZnqtwQ</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-14 21:30:33</td>\n",
       "      <td>0</td>\n",
       "      <td>GJXCdrto3ASJOqKeVWPi6Q</td>\n",
       "      <td>5</td>\n",
       "      <td>I *adore* Travis at the Hard Rock's new Kelly ...</td>\n",
       "      <td>0</td>\n",
       "      <td>yXQM5uF2jS6es16SJzNHfg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WTqjgwHlXbSFevF32_DJVw</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-11-09 20:09:03</td>\n",
       "      <td>0</td>\n",
       "      <td>2TzJjDVDEuAW6MR5Vuc1ug</td>\n",
       "      <td>5</td>\n",
       "      <td>I have to say that this office really has it t...</td>\n",
       "      <td>3</td>\n",
       "      <td>n6-Gk65cPZL6Uz8qRm3NYw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ikCg8xy5JIg_NGPx-MSIDA</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-09 20:56:38</td>\n",
       "      <td>0</td>\n",
       "      <td>yi0R0Ugj_xUx_Nek0-_Qig</td>\n",
       "      <td>5</td>\n",
       "      <td>Went in for a lunch. Steak sandwich was delici...</td>\n",
       "      <td>0</td>\n",
       "      <td>dacAIZ6fTM6mqwW5uxkskg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b1b1eb3uo-w561D0ZfCEiQ</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-30 23:07:38</td>\n",
       "      <td>0</td>\n",
       "      <td>11a8sVPMUFtaC7_ABRkmtw</td>\n",
       "      <td>1</td>\n",
       "      <td>Today was my second out of three sessions I ha...</td>\n",
       "      <td>7</td>\n",
       "      <td>ssoyf2_x0EQMed6fgHeMyQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id  cool                date  funny  \\\n",
       "0  ujmEBvifdJM6h6RLv4wQIg     0 2013-05-07 04:34:36      1   \n",
       "1  NZnhc2sEQy3RmzKTZnqtwQ     0 2017-01-14 21:30:33      0   \n",
       "2  WTqjgwHlXbSFevF32_DJVw     0 2016-11-09 20:09:03      0   \n",
       "3  ikCg8xy5JIg_NGPx-MSIDA     0 2018-01-09 20:56:38      0   \n",
       "4  b1b1eb3uo-w561D0ZfCEiQ     0 2018-01-30 23:07:38      0   \n",
       "\n",
       "                review_id  stars  \\\n",
       "0  Q1sbwvVQXV2734tPgoKj4Q      1   \n",
       "1  GJXCdrto3ASJOqKeVWPi6Q      5   \n",
       "2  2TzJjDVDEuAW6MR5Vuc1ug      5   \n",
       "3  yi0R0Ugj_xUx_Nek0-_Qig      5   \n",
       "4  11a8sVPMUFtaC7_ABRkmtw      1   \n",
       "\n",
       "                                                text  useful  \\\n",
       "0  Total bill for this horrible service? Over $8G...       6   \n",
       "1  I *adore* Travis at the Hard Rock's new Kelly ...       0   \n",
       "2  I have to say that this office really has it t...       3   \n",
       "3  Went in for a lunch. Steak sandwich was delici...       0   \n",
       "4  Today was my second out of three sessions I ha...       7   \n",
       "\n",
       "                  user_id  \n",
       "0  hG7b0MtEbXx5QzbzE6C_VA  \n",
       "1  yXQM5uF2jS6es16SJzNHfg  \n",
       "2  n6-Gk65cPZL6Uz8qRm3NYw  \n",
       "3  dacAIZ6fTM6mqwW5uxkskg  \n",
       "4  ssoyf2_x0EQMed6fgHeMyQ  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  -1,    0,    1,    2,    3,    4,    5,    6,    7,    8,    9,\n",
       "         10,   11,   12,   13,   14,   15,   16,   17,   18,   19,   20,\n",
       "         21,   22,   23,   24,   25,   26,   27,   28,   29,   30,   31,\n",
       "         32,   33,   34,   35,   36,   37,   38,   39,   40,   41,   42,\n",
       "         43,   44,   45,   46,   47,   48,   49,   50,   51,   52,   53,\n",
       "         54,   55,   56,   57,   58,   59,   60,   61,   62,   63,   64,\n",
       "         65,   66,   67,   68,   69,   70,   71,   72,   73,   74,   75,\n",
       "         76,   77,   78,   79,   80,   81,   82,   83,   84,   85,   86,\n",
       "         87,   88,   89,   90,   91,   92,   93,   94,   95,   96,   97,\n",
       "         98,   99,  100,  101,  102,  103,  104,  105,  106,  107,  108,\n",
       "        109,  110,  111,  112,  113,  114,  115,  116,  117,  118,  119,\n",
       "        120,  121,  122,  123,  124,  125,  126,  127,  128,  129,  130,\n",
       "        131,  132,  133,  134,  135,  136,  137,  139,  140,  141,  142,\n",
       "        143,  144,  145,  146,  147,  148,  149,  150,  151,  153,  154,\n",
       "        155,  156,  158,  159,  160,  161,  162,  163,  164,  165,  166,\n",
       "        167,  168,  169,  171,  172,  173,  175,  176,  177,  178,  179,\n",
       "        180,  181,  182,  183,  184,  185,  187,  188,  189,  190,  191,\n",
       "        193,  194,  196,  197,  198,  199,  200,  201,  202,  203,  204,\n",
       "        207,  208,  209,  210,  211,  212,  213,  214,  215,  216,  217,\n",
       "        218,  220,  222,  223,  225,  228,  229,  232,  235,  239,  241,\n",
       "        244,  247,  249,  251,  255,  256,  257,  260,  266,  267,  271,\n",
       "        272,  273,  274,  275,  276,  278,  280,  283,  284,  285,  287,\n",
       "        292,  303,  305,  306,  308,  311,  312,  317,  320,  321,  328,\n",
       "        333,  337,  338,  339,  354,  358,  360,  362,  364,  373,  377,\n",
       "        382,  401,  405,  414,  419,  450,  467,  498,  500,  507,  509,\n",
       "        514,  526,  538,  539,  578,  650,  668,  694,  781,  808,  846,\n",
       "        970, 1122, 1241])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usefulValues = review_df.useful.unique()\n",
    "\n",
    "usefulValues.sort()\n",
    "\n",
    "usefulValues\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
