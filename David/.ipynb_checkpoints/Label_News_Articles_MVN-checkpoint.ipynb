{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stock_data=pd.read_csv(\"./stock_data.csv\")\n",
    "stock_data=pd.read_csv(\"./stock_data_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stock_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_df={}\n",
    "for col in range(stock_data.shape[1]):\n",
    "    if col>0:\n",
    "        stock_df[stock_data.columns[col]]=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means_list=[np.nan]\n",
    "for col in range(stock_data.shape[1]):\n",
    "    if col>0:\n",
    "        dt=stock_data[stock_data.columns[col]][stock_data[stock_data.columns[col]].isnull()==False].reset_index()\n",
    "        colmean=np.mean([float(eval(dt.iloc[i,1])['4. close']) for i in range(dt.shape[0]) ])\n",
    "        means_list.append(colmean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in range(stock_data.shape[1]):\n",
    "    for row in range(stock_data.shape[0]):\n",
    "        if col>0:\n",
    "            try:\n",
    "                stock_df[stock_data.columns[col]].append(eval(stock_data.iloc[row,col])['4. close'])\n",
    "            except TypeError:\n",
    "                print(f\"{row},{col}\")\n",
    "                #stock_df[stock_data.columns[col]].append(stock_df[stock_data.columns[col]][-1])\n",
    "                stock_df[stock_data.columns[col]].append(means_list[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(stock_df)\n",
    "\n",
    "df['Date']=stock_data.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=pd.melt(df, id_vars=['Date'], value_vars=stock_data.columns[1:])\n",
    "\n",
    "df2=df2.rename(columns={'Date':'Close_Date',\n",
    "             'variable':'Symbol',\n",
    "             'value':'Close_Price'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Close_Date']=pd.to_datetime(df2['Close_Date'])\n",
    "\n",
    "df2=df2.sort_values(['Symbol','Close_Date'])\n",
    "\n",
    "df2['Close_Price_Next_Day'] = df2.groupby(['Symbol'])['Close_Price'].shift(-1)\n",
    "\n",
    "df2=df2[df2['Close_Price_Next_Day'].notnull()]\n",
    "\n",
    "df2['Daily_Return']=pd.to_numeric(df2['Close_Price_Next_Day'])/pd.to_numeric(df2['Close_Price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_quantiles={}\n",
    "stock_quantiles['lower_limit']=df2.groupby(['Symbol'])['Daily_Return'].quantile(.1)\n",
    "stock_quantiles['upper_limit']=df2.groupby(['Symbol'])['Daily_Return'].quantile(.9)\n",
    "quantile_df=pd.DataFrame(stock_quantiles).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df=df2.merge(quantile_df, on=['Symbol'], how='left')\n",
    "clean_df['Action_for_News_Date']='Hold'\n",
    "clean_df.loc[(clean_df['Daily_Return'] >clean_df['lower_limit']) & (clean_df['Daily_Return'] <clean_df['upper_limit']), 'Action_for_News_Date'] = 'Hold'\n",
    "clean_df.loc[(clean_df['Daily_Return'] <=clean_df['lower_limit']), 'Action_for_News_Date'] = 'Sell'\n",
    "clean_df.loc[(clean_df['Daily_Return'] >=clean_df['upper_limit']), 'Action_for_News_Date'] = 'Buy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df=clean_df[['Close_Date','Symbol','Action_for_News_Date']]\n",
    "\n",
    "clean_df=clean_df.pivot(index='Close_Date', columns='Symbol', values='Action_for_News_Date')\n",
    "\n",
    "clean_df=clean_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_df.iloc[0,:].value_counts()['Hold']\n",
    "# clean_df['Hold']=0\n",
    "# clean_df['Buy']=0\n",
    "# clean_df['Sell']=0\n",
    "# for row in range(clean_df.shape[0]):\n",
    "#     try:\n",
    "#         clean_df['Hold'][row]=clean_df.iloc[row,:].value_counts()['Hold']\n",
    "#         clean_df['Buy'][row]=clean_df.iloc[row,:].value_counts()['Buy']\n",
    "#         clean_df['Sell'][row]=clean_df.iloc[row,:].value_counts()['Sell']\n",
    "#     except KeyError:\n",
    "#         print(row)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.iloc[0,:].value_counts()['Hold']\n",
    "\n",
    "clean_df['Hold']=0\n",
    "clean_df['Buy']=0\n",
    "clean_df['Sell']=0\n",
    "for row in range(clean_df.shape[0]):\n",
    "    hold=0\n",
    "    buy=0\n",
    "    sell=0\n",
    "    for col in range(clean_df.shape[1]):\n",
    "        if (clean_df.iloc[row,col]==\"Hold\"):\n",
    "            hold+=1\n",
    "        elif (clean_df.iloc[row,col]==\"Buy\"):\n",
    "            buy+=1\n",
    "        else:\n",
    "            sell+=1\n",
    "                #simul_clean_df['Hold'][row]=simul_clean_df.iloc[row,:].value_counts()['Hold']\n",
    "        #simul_clean_df['Buy'][row]=simul_clean_df.iloc[row,:].value_counts()['Buy']\n",
    "        #simul_clean_df['Sell'][row]=simul_clean_df.iloc[row,:].value_counts()['Sell']\n",
    "        \n",
    "    clean_df.loc[row,'Hold']=hold\n",
    "    clean_df.loc[row,'Buy']=buy\n",
    "    clean_df.loc[row,'Sell']=sell  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df['check']=clean_df['Hold']+clean_df['Buy']+clean_df['Sell']\n",
    "\n",
    "clean_df=clean_df[['Close_Date','Hold','Buy','Sell']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df['Buy']=(clean_df['Buy']//2)*2\n",
    "clean_df['Sell']==(clean_df['Sell']//2)*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_df=pd.read_csv(\"Data/Conditional_Buy_Quantile.csv\")\n",
    "ds_df=pd.read_csv(\"Data/Conditional_Sell_Quantile.csv\")\n",
    "db_df.loc[db_df['Sell']==116,:]\n",
    "\n",
    "clean_df=clean_df.merge(db_df, on=['Sell'], how='left')\n",
    "clean_df=clean_df.merge(ds_df, on=['Buy'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df=clean_df[['Close_Date','Hold','Buy','buy_q_0.90','Sell','sell_q_0.90']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df['Action_for_News_Date']=\"Hold\"\n",
    "for row in range(clean_df.shape[0]):\n",
    "    if (clean_df.loc[row,'Buy']>=clean_df.loc[row,'buy_q_0.90']):\n",
    "        if (clean_df.loc[row,'Sell']>=clean_df.loc[row,'sell_q_0.90']):\n",
    "            if (clean_df.loc[row,'Buy']>=clean_df.loc[row,'Sell']):\n",
    "                clean_df.loc[row,'Action_for_News_Date']=\"Buy\"\n",
    "            else:\n",
    "                clean_df.loc[row,'Action_for_News_Date']=\"Sell\"\n",
    "        else:\n",
    "            clean_df.loc[row,'Action_for_News_Date']=\"Buy\"\n",
    "    elif (clean_df.loc[row,'Sell']>=clean_df.loc[row,'sell_q_0.90']):\n",
    "        clean_df.loc[row,'Action_for_News_Date']='Sell'\n",
    "    else:\n",
    "        clean_df.loc[row,'Action_for_News_Date']=\"Hold\"\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df=clean_df[['Close_Date','Action_for_News_Date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_stories={}\n",
    "news_stories['Date']=[]\n",
    "news_stories['content']=[]\n",
    "news_stories['title']=[]\n",
    "news_stories['category']=[]\n",
    "news_stories['id']=[]\n",
    "news_stories['sourceurl']=[]\n",
    "news_stories['imageurl']=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../Data/articles.json\") as jsonFile:\n",
    "   sourceData = json.load(jsonFile)\n",
    "for article in sourceData['articles']:\n",
    "    #print(article)\n",
    "    date=str(article['publishdate'])\n",
    "    news_stories['Date'].append(date[0:4]+\"-\"+date[4:6]+\"-\"+date[6:8])\n",
    "    news_stories['content'].append(article['content'])\n",
    "    news_stories['title'].append(article['title'])\n",
    "    news_stories['category'].append(article['category'])\n",
    "    news_stories['id'].append(article['id'])\n",
    "    news_stories['sourceurl'].append(article['sourceurl'])\n",
    "    news_stories['imageurl'].append(article['imageurl'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_stories_df=pd.DataFrame(news_stories)\n",
    "news_stories_df['Date']=pd.to_datetime(news_stories_df['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_stories_labelled=news_stories_df.merge(clean_df,left_on='Date',right_on='Close_Date',how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "labelled_stories={}\n",
    "labelled_stories['createdate']=time.strftime(\"%Y-%m-%d\")\n",
    "labelled_stories['articles']=[]\n",
    "for row in range(news_stories_labelled.shape[0]):\n",
    "    article={}\n",
    "    article['publishdate']=str(news_stories_labelled.loc[row,'Date'].date().year)+\\\n",
    "    \"-\"+str(news_stories_labelled.loc[row,'Date'].date().month).rjust(2,'0')+\"-\"+\\\n",
    "    str(news_stories_labelled.loc[row,'Date'].date().day).rjust(2,'0')\n",
    "    article['content']=news_stories_labelled.loc[row,'content']\n",
    "    article['label']=news_stories_labelled.loc[row,'Action_for_News_Date']\n",
    "    article['title']=news_stories_labelled.loc[row,'title']\n",
    "    article['category']=news_stories_labelled.loc[row,'category']\n",
    "    article['id']=news_stories_labelled.loc[row,'id']\n",
    "    article['sourceurl']=news_stories_labelled.loc[row,'sourceurl']\n",
    "    article['imageurl']=news_stories_labelled.loc[row,'imageurl']\n",
    "    labelled_stories['articles'].append(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"labelled_stories keys\")\n",
    "print(labelled_stories.keys())\n",
    "print(\"article keys\")\n",
    "print(labelled_stories['articles'][0].keys())\n",
    "print(\"number of articles\")\n",
    "print(len(labelled_stories['articles']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('3.News_With_Labels.json', 'w') as outfile:  \n",
    "    json.dump(labelled_stories, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Data/3.News_With_Labels.json', 'w') as outfile:  \n",
    "    json.dump(labelled_stories, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
