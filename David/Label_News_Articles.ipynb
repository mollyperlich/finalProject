{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stock_data=pd.read_csv(\"./stock_data.csv\")\n",
    "stock_data=pd.read_csv(\"./stock_data_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stock_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_df={}\n",
    "for col in range(stock_data.shape[1]):\n",
    "    if col>0:\n",
    "        stock_df[stock_data.columns[col]]=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means_list=[np.nan]\n",
    "for col in range(stock_data.shape[1]):\n",
    "    if col>0:\n",
    "        dt=stock_data[stock_data.columns[col]][stock_data[stock_data.columns[col]].isnull()==False].reset_index()\n",
    "        colmean=np.mean([float(eval(dt.iloc[i,1])['4. close']) for i in range(dt.shape[0]) ])\n",
    "        means_list.append(colmean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in range(stock_data.shape[1]):\n",
    "    for row in range(stock_data.shape[0]):\n",
    "        if col>0:\n",
    "            try:\n",
    "                stock_df[stock_data.columns[col]].append(eval(stock_data.iloc[row,col])['4. close'])\n",
    "            except TypeError:\n",
    "                print(f\"{row},{col}\")\n",
    "                #stock_df[stock_data.columns[col]].append(stock_df[stock_data.columns[col]][-1])\n",
    "                stock_df[stock_data.columns[col]].append(means_list[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(stock_df)\n",
    "\n",
    "df['Date']=stock_data.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=pd.melt(df, id_vars=['Date'], value_vars=stock_data.columns[1:])\n",
    "\n",
    "df2=df2.rename(columns={'Date':'Close_Date',\n",
    "             'variable':'Symbol',\n",
    "             'value':'Close_Price'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Close_Date']=pd.to_datetime(df2['Close_Date'])\n",
    "\n",
    "df2=df2.sort_values(['Symbol','Close_Date'])\n",
    "\n",
    "df2['Close_Price_Next_Day'] = df2.groupby(['Symbol'])['Close_Price'].shift(-1)\n",
    "\n",
    "df2=df2[df2['Close_Price_Next_Day'].notnull()]\n",
    "\n",
    "df2['Daily_Return']=pd.to_numeric(df2['Close_Price_Next_Day'])/pd.to_numeric(df2['Close_Price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_quantiles={}\n",
    "stock_quantiles['lower_limit']=df2.groupby(['Symbol'])['Daily_Return'].quantile(.1)\n",
    "stock_quantiles['upper_limit']=df2.groupby(['Symbol'])['Daily_Return'].quantile(.9)\n",
    "quantile_df=pd.DataFrame(stock_quantiles).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df=df2.merge(quantile_df, on=['Symbol'], how='left')\n",
    "clean_df['Action_for_News_Date']='Hold'\n",
    "clean_df.loc[(clean_df['Daily_Return'] >clean_df['lower_limit']) & (clean_df['Daily_Return'] <clean_df['upper_limit']), 'Action_for_News_Date'] = 'Hold'\n",
    "clean_df.loc[(clean_df['Daily_Return'] <=clean_df['lower_limit']), 'Action_for_News_Date'] = 'Sell'\n",
    "clean_df.loc[(clean_df['Daily_Return'] >=clean_df['upper_limit']), 'Action_for_News_Date'] = 'Buy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df=clean_df[['Close_Date','Symbol','Action_for_News_Date']]\n",
    "\n",
    "clean_df=clean_df.pivot(index='Close_Date', columns='Symbol', values='Action_for_News_Date')\n",
    "\n",
    "clean_df=clean_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.iloc[0,:].value_counts()['Hold']\n",
    "clean_df['Hold']=0\n",
    "clean_df['Buy']=0\n",
    "clean_df['Sell']=0\n",
    "for row in range(clean_df.shape[0]):\n",
    "    try:\n",
    "        clean_df['Hold'][row]=clean_df.iloc[row,:].value_counts()['Hold']\n",
    "        clean_df['Buy'][row]=clean_df.iloc[row,:].value_counts()['Buy']\n",
    "        clean_df['Sell'][row]=clean_df.iloc[row,:].value_counts()['Sell']\n",
    "    except KeyError:\n",
    "        print(row)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df['check']=clean_df['Hold']+clean_df['Buy']+clean_df['Sell']\n",
    "\n",
    "clean_df=clean_df[['Close_Date','Hold','Buy','Sell']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_count=sum(clean_df['Hold'])+sum(clean_df['Buy'])+sum(clean_df['Sell'])\n",
    "p_hold=sum(clean_df['Hold'])/total_count\n",
    "p_buy=sum(clean_df['Buy'])/total_count\n",
    "p_sell=sum(clean_df['Sell'])/total_count\n",
    "print(f\"Hold:{p_hold},Buy:{p_buy},Sell:{p_sell}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import binom\n",
    "n=len(stock_data.columns)-1\n",
    "p=.1\n",
    "decision_threshold=np.quantile(binom.rvs(n, p, size=10000),.9)\n",
    "print(f\"If either Buy or Sell count >={decision_threshold},label accordingly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df['Action_for_News_Date']='Hold'\n",
    "clean_df.loc[clean_df['Sell']>=decision_threshold,'Action_for_News_Date']=\"Sell\"\n",
    "clean_df.loc[clean_df['Buy']>=decision_threshold,'Action_for_News_Date']=\"Buy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df=clean_df[['Close_Date','Action_for_News_Date']]\n",
    "clean_df.groupby('Action_for_News_Date')['Close_Date'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_stories={}\n",
    "news_stories['Date']=[]\n",
    "news_stories['content']=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../Data/articles.json\") as jsonFile:\n",
    "   sourceData = json.load(jsonFile)\n",
    "for article in sourceData['articles']:\n",
    "    #print(article)\n",
    "    date=str(article['publishdate'])\n",
    "    news_stories['Date'].append(date[0:4]+\"-\"+date[4:6]+\"-\"+date[6:8])\n",
    "    news_stories['content'].append(article['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_stories_df=pd.DataFrame(news_stories)\n",
    "news_stories_df['Date']=pd.to_datetime(news_stories_df['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_stories_labelled=news_stories_df.merge(clean_df,left_on='Date',right_on='Close_Date',how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "labelled_stories={}\n",
    "labelled_stories['createdate']=time.strftime(\"%Y-%m-%d\")\n",
    "labelled_stories['articles']=[]\n",
    "for row in range(news_stories_labelled.shape[0]):\n",
    "    article={}\n",
    "    article['publishdate']=str(news_stories_labelled.loc[row,'Date'].date().month)+\"/\"+str(news_stories_labelled.loc[row,'Date'].date().day)+\"/\"+str(news_stories_labelled.loc[row,'Date'].date().year)\n",
    "    article['content']=news_stories_labelled.loc[row,'content']\n",
    "    article['label']=news_stories_labelled.loc[row,'Action_for_News_Date']\n",
    "    labelled_stories['articles'].append(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('2.News_With_Labels.json', 'w') as outfile:  \n",
    "    json.dump(labelled_stories, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Data/2.News_With_Labels.json', 'w') as outfile:  \n",
    "    json.dump(labelled_stories, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
